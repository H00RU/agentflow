device: "cuda"

# MCTS + Qwen直接生成代码配置
# MCTS tree search with Qwen direct code generation
#
# 对齐原版AFlow + VERL，不简化训练流程，无超出框架创新

total_epochs: 10
episodes_per_epoch: 6
update_frequency: 1
eval_episodes: 2
save_frequency: 1

output_dir: "/content/drive/MyDrive/agentflow/outputs/mcts_qwen"
experience_pool_size: 500

environment:
  train_datasets:
    - "AIME"
  test_datasets:
    - "AIME"
  data_path: "/content/agentflow/AFlow/data/AIME_2024.jsonl"
  train_test_split: 0.8

  # 优化LLM配置（仅用于fallback，主要使用Qwen）
  opt_llm_config:
    model: "gpt-4o-mini"
    key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    temperature: 0.9

  exec_llm_config:
    model: "gpt-4o-mini"
    key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    temperature: 0.7

  operators:
    - "Custom"
    - "ScEnsemble"
    - "Test"
    - "Review"
    - "Revise"

  env_num: 1
  group_n: 1
  max_rounds: 5
  validation_rounds: 3
  sample: 24

  # ✨ MCTS + Qwen直接生成核心配置
  use_dynamic_optimizer: true  # 启用MCTS树搜索
  rl_weight: 0.5  # UCB + Q-value融合权重

  # ✨ 启用Qwen直接生成代码（替代GPT-4）
  use_qwen_code_generation: true  # 让Qwen直接生成完整Python代码
  qwen_max_retries: 2  # Qwen语法错误时的最大重试次数

  workflow_sample_count: 15

rl:
  policy:
    model_path: "/root/models/Qwen2.5-7B-Instruct"
    use_lora: true
    lora_r: 16
    lora_alpha: 32
    value_head_dim: 1024

  learning_rate: 0.00003
  batch_size: 4
  ppo_epochs: 4
  ppo_clip: 0.2
  gamma: 0.99
  gae_lambda: 0.95
  value_coef: 0.5
  entropy_coef: 0.03
  gradient_clip: 1.0

  gigpo:
    enable: true
    epsilon: 0.000001
    step_advantage_w: 1.0
    mode: "mean_norm"
    enable_similarity: true
    similarity_thresh: 0.95
    workflow_similarity_thresh: 0.8

logging:
  level: "INFO"

debug:
  verbose_env: true
