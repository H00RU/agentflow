"""
Deep Workflow Environment with Meta Learning - é›†æˆå…ƒå­¦ä¹ çš„workflowç¯å¢ƒ
Enhanced version of deep_workflow_env.py with meta-learning integration

ä¸»è¦æ”¹è¿›ï¼š
1. ä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©å™¨æ›¿ä»£ç¡¬ç¼–ç çš„parser
2. è‡ªåŠ¨è®°å½•æ¯æ¬¡æ‰§è¡Œç»éªŒ
3. æ”¯æŒè¶Šç»ƒè¶Šå¼º
"""

import sys
import os
import asyncio
import shutil
import importlib
from typing import List, Tuple, Dict, Optional
import numpy as np

# Add paths
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'AFlow'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'AFlow', 'scripts'))

from scripts.logs import logger
from scripts.evaluator import DatasetType
from workflow_parser import WorkflowParser, WorkflowSpec
from workflow_evaluator import WorkflowEvaluator

# å¯¼å…¥å…ƒå­¦ä¹ ç»„ä»¶
from meta_learning_integration import MetaLearningIntegration


class DeepWorkflowEnvWithMeta:
    """
    æ·±åº¦é›†æˆçš„Workflowç¯å¢ƒ + å…ƒå­¦ä¹ 

    æ–°åŠŸèƒ½ï¼š
    1. ä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©å™¨æ™ºèƒ½é€‰æ‹©operators
    2. è‡ªåŠ¨è®°å½•æ‰§è¡Œç»éªŒ
    3. è¶Šç»ƒè¶Šå¼ºçš„operatoré€‰æ‹©
    """

    def __init__(
        self,
        dataset: str,
        opt_llm_config: Dict,
        exec_llm_config: Dict,
        operators: List[str],
        env_num: int = 2,
        sample: int = 3,
        max_rounds: int = 10,
        workspace_path: str = None,
        enable_meta_learning: bool = True,  # æ–°å¢ï¼šæ˜¯å¦å¯ç”¨å…ƒå­¦ä¹ 
        meta_save_dir: str = None  # æ–°å¢ï¼šå…ƒå­¦ä¹ ä¿å­˜ç›®å½•
    ):
        """
        åˆå§‹åŒ–çœŸå®workflowç¯å¢ƒ + å…ƒå­¦ä¹ 

        Args:
            dataset: æ•°æ®é›†åç§°ï¼ˆå¦‚"HumanEval"ï¼‰
            opt_llm_config: ä¼˜åŒ–LLMé…ç½®
            exec_llm_config: æ‰§è¡ŒLLMé…ç½®
            operators: å¯ç”¨çš„operatorsåˆ—è¡¨ï¼ˆå…ƒå­¦ä¹ æ¨¡å¼ä¸‹ä½œä¸ºå‚è€ƒï¼‰
            env_num: å¹¶è¡Œç¯å¢ƒæ•°é‡
            sample: æ¯è½®æµ‹è¯•çš„æ ·æœ¬æ•°
            max_rounds: æœ€å¤§è½®æ•°
            workspace_path: workspaceè·¯å¾„
            enable_meta_learning: æ˜¯å¦å¯ç”¨å…ƒå­¦ä¹ 
            meta_save_dir: å…ƒå­¦ä¹ æ•°æ®ä¿å­˜ç›®å½•
        """
        self.dataset = dataset
        self.opt_llm_config = opt_llm_config
        self.exec_llm_config = exec_llm_config
        self.operators = operators
        self.env_num = env_num
        self.sample = sample
        self.max_rounds = max_rounds
        self.enable_meta_learning = enable_meta_learning

        # Workspaceè·¯å¾„
        if workspace_path is None:
            aflow_path = os.path.join(os.path.dirname(__file__), '..', 'AFlow')
            self.workspace_path = os.path.join(aflow_path, 'workspace', dataset, 'workflows_rl')
        else:
            self.workspace_path = workspace_path

        os.makedirs(self.workspace_path, exist_ok=True)

        # å…ƒå­¦ä¹ é›†æˆï¼ˆæ–°å¢ï¼‰
        if self.enable_meta_learning:
            self.meta_integration = MetaLearningIntegration(
                save_dir=meta_save_dir,
                enable_meta_learning=True,
                enable_adaptation=False  # ç¯å¢ƒä¸­ä¸ä½¿ç”¨è‡ªé€‚åº”ï¼Œåªä½¿ç”¨é€‰æ‹©å™¨
            )
            logger.info("[DeepWorkflowEnvWithMeta] âœ… Meta learning ENABLED")
        else:
            self.meta_integration = None
            logger.info("[DeepWorkflowEnvWithMeta] âš ï¸  Meta learning DISABLED")

        # ä¿ç•™åŸå§‹parserä½œä¸ºfallback
        self.fallback_parser = WorkflowParser()

        # åˆ›å»ºevaluator
        if self.dataset.upper() == "AIME":
            from aime_evaluator import AIMEEvaluator
            import asyncio
            self.evaluator = AIMEEvaluator(
                llm_config=self.exec_llm_config,
                dataset_path="/content/agentflow/AFlow/data/AIME_2024.jsonl"
            )
            # AIMEEvaluatoréœ€è¦å¼‚æ­¥åˆå§‹åŒ–åŠ è½½æ•°æ®é›†
            asyncio.run(self.evaluator.initialize())
            logger.info(f"[DeepWorkflowEnvWithMeta] Using AIMEEvaluator")
        else:
            self.evaluator = WorkflowEvaluator(
                dataset=self.dataset,
                sample_size=sample,
                timeout_per_problem=30
            )
            logger.info(f"[DeepWorkflowEnvWithMeta] Using WorkflowEvaluator for {self.dataset}")

        # å½“å‰çŠ¶æ€
        self.current_round = 0
        self.workflow_history = []
        self.best_score = 0.0
        self.best_workflow = None

        # ç»Ÿè®¡ï¼ˆæ–°å¢ï¼šç”¨äºè®°å½•å…ƒå­¦ä¹ ä¿¡æ¯ï¼‰
        self.execution_history = []  # è®°å½•æ¯æ¬¡æ‰§è¡Œçš„è¯¦ç»†ä¿¡æ¯

        # ç»Ÿè®¡
        self.total_api_calls = 0
        self.total_tests_run = 0

        logger.info(f"[DeepWorkflowEnvWithMeta] Initialized")
        logger.info(f"[DeepWorkflowEnvWithMeta] Dataset: {dataset}")
        logger.info(f"[DeepWorkflowEnvWithMeta] Workspace: {self.workspace_path}")

    def reset(self) -> Tuple[List[str], List[Dict]]:
        """é‡ç½®ç¯å¢ƒ"""
        self.current_round = 0

        observations = []
        info = []

        for i in range(self.env_num):
            obs = self._construct_observation(
                round_num=0,
                best_score=self.best_score,
                history=self._get_history_summary()
            )
            observations.append(obs)

            info_dict = {
                'step': 0,
                'round': 0,
                'env_id': i,
                'best_score': self.best_score,
                'workflow_path': None
            }
            info.append(info_dict)

        logger.info(f"[DeepWorkflowEnvWithMeta] Environment reset")
        return observations, info

    def step(self, actions: List[str]) -> Tuple[List[str], List[float], List[bool], List[Dict]]:
        """
        æ‰§è¡Œstep - ä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©å™¨

        ä¸»è¦æ”¹è¿›ï¼š
        1. ä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©operatorsï¼ˆè€Œä¸æ˜¯Qwenè¾“å‡ºï¼‰
        2. è®°å½•æ‰§è¡Œç»éªŒ
        """
        import time
        self.current_round += 1

        next_observations = []
        rewards = []
        dones = []
        info = []

        logger.info(f"[DeepWorkflowEnvWithMeta] ===== Round {self.current_round} =====")

        for i, qwen_action in enumerate(actions):
            start_time = time.time()

            try:
                logger.info(f"[DeepWorkflowEnvWithMeta] Env {i}: Processing action...")

                # ===== å…³é”®æ”¹è¿›ï¼šä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©å™¨ =====
                if self.enable_meta_learning:
                    # æ–¹æ¡ˆ1ï¼šç›´æ¥ä»Qwen actionä¸­æå–é—®é¢˜æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
                    # æˆ–è€…ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„é—®é¢˜æè¿°
                    problem_desc = self._extract_problem_desc(qwen_action)

                    # ä½¿ç”¨å…ƒå­¦ä¹ é€‰æ‹©å™¨é€‰æ‹©operators
                    selection = self.meta_integration.parse_and_select_operators(
                        problem=problem_desc,
                        dataset_type=self.dataset
                    )

                    logger.info(f"[DeepWorkflowEnvWithMeta] Env {i}: Meta selector chose:")
                    logger.info(f"  Strategy: {selection['strategy_name']}")
                    logger.info(f"  Operators: {selection['operators']}")
                    logger.info(f"  Confidence: {selection['confidence']:.3f}")

                    # ä½¿ç”¨é€‰æ‹©çš„operatorsç”Ÿæˆworkflowä»£ç 
                    workflow_code = selection.get('workflow_code')
                    if workflow_code:
                        workflow_spec = WorkflowSpec(
                            modification=f"Meta-learned: {selection['strategy_name']}",
                            operators=selection['operators'],
                            steps=[selection.get('description', '')],
                            workflow_code=workflow_code
                        )
                    else:
                        # Fallbackï¼šä½¿ç”¨ä¼ ç»Ÿparser
                        logger.warning(f"[DeepWorkflowEnvWithMeta] No workflow code, using fallback")
                        workflow_spec = self.fallback_parser.parse_qwen_output(
                            qwen_action,
                            dataset_type=self.dataset
                        )
                else:
                    # ä¸ä½¿ç”¨å…ƒå­¦ä¹ ï¼Œé€€å›åˆ°ä¼ ç»Ÿparser
                    workflow_spec = self.fallback_parser.parse_qwen_output(
                        qwen_action,
                        dataset_type=self.dataset
                    )

                if workflow_spec is None:
                    logger.error(f"[DeepWorkflowEnvWithMeta] Env {i}: Failed to create workflow!")
                    rewards.append(0.0)
                    next_observations.append(self._construct_observation(
                        self.current_round, self.best_score, "Workflow creation failed"
                    ))
                    dones.append(False)
                    info.append({'step': self.current_round, 'error': 'creation_failed'})
                    continue

                # 2. ä¿å­˜workflowä»£ç 
                round_id = f"{self.current_round}_env{i}"
                workflow_path = self._save_workflow(workflow_spec, round_id)

                logger.info(f"[DeepWorkflowEnvWithMeta] Env {i}: Workflow saved to {workflow_path}")

                # 3. æ‰§è¡Œworkflowå¹¶è·å–çœŸå®åˆ†æ•°
                score, cost = self._execute_workflow(workflow_path)
                execution_time = time.time() - start_time

                logger.info(f"[DeepWorkflowEnvWithMeta] Env {i}: Score = {score:.4f}, Cost = ${cost:.4f}")

                # ===== å…³é”®æ”¹è¿›ï¼šè®°å½•ç»éªŒåˆ°å…ƒå­¦ä¹ ç³»ç»Ÿ =====
                if self.enable_meta_learning:
                    # è®°å½•è¿™æ¬¡æ‰§è¡Œçš„ç»éªŒ
                    self.meta_integration.record_execution(
                        problem=problem_desc,
                        dataset_type=self.dataset,
                        solution=f"operators: {workflow_spec.operators}",
                        expected_answer=None,  # ç¯å¢ƒçº§åˆ«æ²¡æœ‰å•ä¸ªç­”æ¡ˆ
                        actual_answer=score,
                        score=score,
                        execution_time=execution_time
                    )

                # è®°å½•åˆ°å†å²
                self.workflow_history.append({
                    'round': self.current_round,
                    'env_id': i,
                    'operators': workflow_spec.operators,
                    'score': score,
                    'cost': cost,
                    'workflow_path': workflow_path
                })

                # æ›´æ–°æœ€ä½³
                if score > self.best_score:
                    self.best_score = score
                    self.best_workflow = workflow_spec
                    logger.info(f"[DeepWorkflowEnvWithMeta] ğŸ‰ New best score: {score:.4f}")

                rewards.append(score)

                # æ„é€ ä¸‹ä¸€ä¸ªè§‚æµ‹
                obs = self._construct_observation(
                    self.current_round,
                    self.best_score,
                    self._get_history_summary()
                )
                next_observations.append(obs)

                # åˆ¤æ–­æ˜¯å¦ç»“æŸ
                done = (self.current_round >= self.max_rounds) or (score >= 0.95)
                dones.append(done)

                info.append({
                    'step': self.current_round,
                    'round': self.current_round,
                    'env_id': i,
                    'score': score,
                    'cost': cost,
                    'best_score': self.best_score,
                    'workflow_path': workflow_path,
                    'operators': workflow_spec.operators
                })

            except Exception as e:
                logger.error(f"[DeepWorkflowEnvWithMeta] Env {i} error: {e}")
                import traceback
                traceback.print_exc()

                rewards.append(0.0)
                next_observations.append(self._construct_observation(
                    self.current_round, self.best_score, f"Error: {str(e)}"
                ))
                dones.append(False)
                info.append({'step': self.current_round, 'error': str(e)})

        return next_observations, rewards, dones, info

    def _extract_problem_desc(self, qwen_action: str) -> str:
        """
        ä»Qwençš„actionä¸­æå–é—®é¢˜æè¿°

        å¦‚æœQwenè¾“å‡ºä¸­åŒ…å«é—®é¢˜æè¿°ï¼Œæå–å®ƒï¼›
        å¦åˆ™è¿”å›ä¸€ä¸ªé€šç”¨æè¿°
        """
        # ç®€å•ç‰ˆæœ¬ï¼šä½¿ç”¨æ•°æ®é›†ç±»å‹ä½œä¸ºé—®é¢˜æè¿°
        # æ›´å¤æ‚çš„ç‰ˆæœ¬å¯ä»¥è§£æQwenè¾“å‡º
        return f"Optimize workflow for {self.dataset} tasks"

    def _save_workflow(self, workflow_spec: WorkflowSpec, round_id: str) -> str:
        """ä¿å­˜workflowåˆ°æ–‡ä»¶"""
        round_dir = os.path.join(self.workspace_path, f"round_{round_id}")
        os.makedirs(round_dir, exist_ok=True)

        graph_path = os.path.join(round_dir, "graph.py")
        with open(graph_path, 'w') as f:
            f.write(workflow_spec.workflow_code)

        return graph_path

    def _execute_workflow(self, workflow_path: str) -> Tuple[float, float]:
        """æ‰§è¡Œworkflowå¹¶è¿”å›åˆ†æ•°"""
        try:
            # åŠ¨æ€åŠ è½½workflow
            workflow_dir = os.path.dirname(workflow_path)
            sys.path.insert(0, workflow_dir)

            import importlib.util
            spec = importlib.util.spec_from_file_location("graph", workflow_path)
            graph_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(graph_module)

            # åˆ›å»ºworkflowå®ä¾‹ - ä½¿ç”¨æ³›ç”¨çš„å­—ç¬¦ä¸²ç±»å‹
            dataset_type = self._str_to_dataset_type(self.dataset)

            workflow = graph_module.Workflow(
                name=f"workflow_{self.current_round}",
                llm_config=self.exec_llm_config,
                dataset=dataset_type  # ç°åœ¨æ˜¯strè€ŒéDatasetTypeæšä¸¾
            )

            # ä½¿ç”¨evaluatorè¯„ä¼°
            # ä¸åŒevaluatorçš„æ¥å£å¯èƒ½ä¸åŒï¼Œéœ€è¦é€‚é…
            import asyncio
            import inspect

            eval_result = self.evaluator.evaluate_workflow(workflow)

            # å¦‚æœæ˜¯coroutineï¼Œéœ€è¦await
            if inspect.iscoroutine(eval_result):
                eval_result = asyncio.run(eval_result)

            # é€‚é…ä¸åŒevaluatorçš„è¿”å›æ ¼å¼
            if isinstance(eval_result, dict):
                # AIMEEvaluatorè¿”å›å­—å…¸
                score = eval_result.get('pass_at_k', 0.0)
                cost = 0.0  # AIME evaluatorä¸è¿½è¸ªcost
            elif isinstance(eval_result, tuple) and len(eval_result) == 2:
                # WorkflowEvaluatorè¿”å›(score, cost)å…ƒç»„
                score, cost = eval_result
            else:
                logger.warning(f"[DeepWorkflowEnvWithMeta] Unexpected evaluator result format: {type(eval_result)}")
                score, cost = 0.0, 0.0

            sys.path.remove(workflow_dir)

            return score, cost

        except Exception as e:
            logger.error(f"[DeepWorkflowEnvWithMeta] Workflow execution error: {e}")
            import traceback
            traceback.print_exc()
            return 0.0, 0.0

    def _construct_observation(self, round_num: int, best_score: float, history: str) -> str:
        """æ„é€ è§‚æµ‹"""
        obs = f"""Current Round: {round_num}/{self.max_rounds}
Best Score So Far: {best_score:.4f}
Dataset: {self.dataset}

History: {history}

Your task: Propose operator combinations to improve workflow performance.
Available operators: {', '.join(self.operators)}
"""
        return obs

    def _get_history_summary(self) -> str:
        """è·å–å†å²æ‘˜è¦"""
        if not self.workflow_history:
            return "No history yet"

        recent = self.workflow_history[-3:]
        summary = []
        for h in recent:
            summary.append(f"Round {h['round']}: operators={h['operators']}, score={h['score']:.3f}")

        return "; ".join(summary)

    def _str_to_dataset_type(self, dataset: str):
        """
        å­—ç¬¦ä¸²è½¬DatasetType - æ³›ç”¨ç‰ˆæœ¬

        ç›´æ¥è¿”å›è§„èŒƒåŒ–çš„æ•°æ®é›†åç§°ï¼Œæ— éœ€ç¡¬ç¼–ç æ‰€æœ‰å¯èƒ½çš„æ•°æ®é›†ã€‚
        è¿™å…è®¸ç³»ç»Ÿè‡ªåŠ¨æ”¯æŒæ–°æ•°æ®é›†ï¼ˆå¦‚AIMEï¼‰è€Œæ— éœ€ä¿®æ”¹æ­¤å‡½æ•°ã€‚
        """
        # è§„èŒƒåŒ–ï¼šé¦–å­—æ¯å¤§å†™ï¼Œå…¶ä½™ä¿æŒåŸæ ·
        # ä¾‹å¦‚: "aime" -> "AIME", "humaneval" -> "HumanEval", "gsm8k" -> "GSM8K"
        dataset_name = dataset.strip()

        # ç‰¹æ®Šå¤„ç†ä¸€äº›å¸¸è§çš„å‘½åçº¦å®š
        special_cases = {
            'humaneval': 'HumanEval',
            'hotpotqa': 'HotpotQA',
            'livecodebench': 'LiveCodeBench',
        }

        lower_name = dataset_name.lower()
        if lower_name in special_cases:
            return special_cases[lower_name]

        # å¯¹äºå…¶ä»–æ•°æ®é›†ï¼ˆåŒ…æ‹¬AIMEï¼‰ï¼Œä½¿ç”¨å…¨å¤§å†™æˆ–ä¿æŒåŸæ ·
        # è¿™æ”¯æŒä»»æ„æ–°æ•°æ®é›†è€Œä¸éœ€è¦ä¿®æ”¹ä»£ç 
        if lower_name.isupper() or len(dataset_name) <= 5:
            return dataset_name.upper()

        return dataset_name

    def print_meta_statistics(self):
        """æ‰“å°å…ƒå­¦ä¹ ç»Ÿè®¡"""
        if self.enable_meta_learning:
            self.meta_integration.print_statistics()

    def save_meta_checkpoint(self):
        """ä¿å­˜å…ƒå­¦ä¹ æ£€æŸ¥ç‚¹"""
        if self.enable_meta_learning:
            self.meta_integration.save_checkpoint()


# å‘åå…¼å®¹çš„å·¥å‚å‡½æ•°
def create_deep_workflow_env(*args, **kwargs):
    """
    åˆ›å»ºç¯å¢ƒçš„å·¥å‚å‡½æ•°

    è‡ªåŠ¨å¯ç”¨å…ƒå­¦ä¹ ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤å¯ç”¨å…ƒå­¦ä¹ 
    if 'enable_meta_learning' not in kwargs:
        kwargs['enable_meta_learning'] = True

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä¿å­˜ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤
    if 'meta_save_dir' not in kwargs:
        if os.path.exists("/content/drive/MyDrive"):
            kwargs['meta_save_dir'] = "/content/drive/MyDrive/agentflow/meta_learning"
        else:
            kwargs['meta_save_dir'] = None  # ä½¿ç”¨é»˜è®¤

    return DeepWorkflowEnvWithMeta(*args, **kwargs)
