# é€‰é¡¹1 vs é€‰é¡¹3 è¯¦ç»†å¯¹æ¯”

## æ ¸å¿ƒé—®é¢˜

**ä½ çš„åˆå¿ƒ**ï¼šç”¨Qwenç”Ÿæˆworkflowï¼Œè®­ç»ƒQwenè¿›åŒ–
**å½“å‰é—®é¢˜**ï¼šä¸ºäº†å¯¹é½AFlowå¼•å…¥äº†GPT-4 fallbackï¼Œè¿èƒŒåˆå¿ƒ

---

## é€‰é¡¹1ï¼šç§»é™¤GPT-4 fallback

### è®¾è®¡

**ä¿ç•™æ¡†æ¶ç»“æ„ï¼Œåªæ”¹ä»£ç ç”Ÿæˆé€»è¾‘**

```python
# optimizer_rl.py: _generate_with_rl_guidance()

async def _generate_with_rl_guidance(...):
    if self.use_qwen_code_generation:
        qwen_response = await self._generate_code_with_qwen(...)

        if qwen_response is not None:
            return qwen_response  # âœ… QwenæˆåŠŸ
        else:
            # âŒ Qwenå¤±è´¥ - ä¸fallbackï¼Œè¿”å›å¤±è´¥ç»“æœ
            return {
                'modification': 'Code generation failed - syntax error',
                'graph': '# Failed workflow\nclass Workflow:\n    def __init__(self, name, llm_config, dataset):\n        pass\n    async def __call__(self, problem, entry_point=None):\n        return "", 0.0',
                'prompt': ''
            }
            # è¿™ä¸ªå¤±è´¥çš„workflowæ‰§è¡Œä¼šå¾—åˆ°0åˆ† â†’ å¼ºè´Ÿå¥–åŠ± â†’ Qwenå­¦ä¹ 

    # å¦‚æœæ²¡å¯ç”¨use_qwen_code_generationï¼Œç”¨åŸç‰ˆGPT-4ï¼ˆå‘åå…¼å®¹ï¼‰
    return await self._generate_graph(enhanced_prompt)
```

### ä¿ç•™çš„æ¡†æ¶ç»„ä»¶

| ç»„ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `Optimizer`åŸºç±» | âœ… å®Œå…¨ä¿ç•™ | ä¸ä¿®æ”¹åŸºç±» |
| `self.optimize_llm` | âœ… ä¿ç•™ | åŸºç±»åˆå§‹åŒ–ï¼Œå‘åå…¼å®¹éœ€è¦ |
| `_generate_graph()` | âœ… ä¿ç•™ | ç”¨äºå‘åå…¼å®¹ï¼ˆGPT-4æ¨¡å¼ï¼‰ |
| `opt_llm_config` | âœ… ä¿ç•™ | é…ç½®ä¸­ä»éœ€è¦ï¼ˆå‘åå…¼å®¹ï¼‰ |
| MCTSæ ‘æœç´¢ | âœ… å®Œå…¨ä¿ç•™ | ä¸ä¿®æ”¹ |
| UCBé€‰æ‹© | âœ… å®Œå…¨ä¿ç•™ | ä¸ä¿®æ”¹ |
| ç»éªŒæ±  | âœ… å®Œå…¨ä¿ç•™ | ä¸ä¿®æ”¹ |
| Roundç»“æ„ | âœ… å®Œå…¨ä¿ç•™ | ä¸ä¿®æ”¹ |

### æ”¹åŠ¨èŒƒå›´

**ä»…ä¿®æ”¹1ä¸ªæ–¹æ³•**ï¼š`_generate_with_rl_guidance()`

```python
# ä¿®æ”¹å‰ï¼ˆå½“å‰ï¼‰
if qwen_response is not None:
    return qwen_response
else:
    logger.warning("Falling back to GPT-4")  # âŒ fallback
```

```python
# ä¿®æ”¹åï¼ˆé€‰é¡¹1ï¼‰
if qwen_response is not None:
    return qwen_response
else:
    logger.warning("Qwen failed, returning empty workflow for negative reward")
    return {...}  # âœ… è¿”å›å¤±è´¥ç»“æœï¼Œè®©Qwenå­¦ä¹ 
```

### é…ç½®è¦æ±‚

**ä»éœ€è¦opt_llm_config**ï¼ˆä½†å¯ä»¥æ˜¯dummyé…ç½®ï¼‰ï¼š

```yaml
environment:
  # å‘åå…¼å®¹éœ€è¦ï¼Œä½†MCTS+Qwenæ¨¡å¼ä¸‹ä¸ä¼šçœŸæ­£è°ƒç”¨
  opt_llm_config:
    model: "gpt-4o-mini"  # å¯ä»¥ä¿ç•™
    key: "${OPENAI_API_KEY}"

  use_dynamic_optimizer: true
  use_qwen_code_generation: true  # å¯ç”¨Qwenï¼Œä¸ä¼šfallback
```

### è®­ç»ƒæµç¨‹å®Œæ•´æ€§

**âœ… å®Œå…¨ä¸ç®€åŒ–**ï¼š

```
Round 1:
  MCTSé€‰æ‹©çˆ¶èŠ‚ç‚¹ï¼ˆrootï¼‰
    â†“
  Qwenç”Ÿæˆä»£ç 
    â†“ æˆåŠŸ
  ä¿å­˜workflow â†’ æ‰§è¡Œ â†’ å¾—åˆ†0.3
    â†“
  æ›´æ–°MCTSæ ‘ï¼ˆQ-value, visitsï¼‰

Round 2:
  MCTSé€‰æ‹©çˆ¶èŠ‚ç‚¹ï¼ˆUCB + Q-valueï¼‰
    â†“
  Qwenç”Ÿæˆä»£ç 
    â†“ å¤±è´¥ï¼ˆè¯­æ³•é”™è¯¯ï¼‰
  è¿”å›å¤±è´¥workflow â†’ æ‰§è¡Œ â†’ å¾—åˆ†0.0
    â†“ å¼ºè´Ÿå¥–åŠ±
  æ›´æ–°MCTSæ ‘
    â†“
  PPOæ›´æ–°ï¼šå­¦ä¹ é¿å…è¯­æ³•é”™è¯¯

Round 3:
  MCTSé€‰æ‹©çˆ¶èŠ‚ç‚¹ï¼ˆé¿å¼€Round 2ï¼‰
    â†“
  Qwenç”Ÿæˆä»£ç ï¼ˆæ”¹è¿›äº†ï¼‰
    â†“ æˆåŠŸ
  ä¿å­˜workflow â†’ æ‰§è¡Œ â†’ å¾—åˆ†0.5
```

**æ ¸å¿ƒ**ï¼š
- âœ… MCTSå®Œæ•´è¿è¡Œ
- âœ… Qwené€šè¿‡å¤±è´¥å­¦ä¹ 
- âœ… è´Ÿå¥–åŠ±ç›´æ¥åé¦ˆ
- âœ… æ²¡æœ‰GPT-4å¹²é¢„

### å‘åå…¼å®¹æ€§

**âœ… 100%å‘åå…¼å®¹**ï¼š

| åœºæ™¯ | è¡Œä¸º |
|------|------|
| `use_qwen_code_generation=false` | ä½¿ç”¨GPT-4ï¼ˆåŸç‰ˆï¼‰ |
| `use_qwen_code_generation=true` | ä½¿ç”¨Qwenï¼Œä¸fallback |
| æ—§é…ç½®æ–‡ä»¶ | æ­£å¸¸å·¥ä½œ |

---

## é€‰é¡¹3ï¼šå®Œå…¨ç§»é™¤GPT-4ä¾èµ–

### è®¾è®¡

**ç§»é™¤æ‰€æœ‰GPT-4ç›¸å…³ä»£ç å’Œé…ç½®**

å¯èƒ½çš„æ”¹åŠ¨ï¼š
1. ç§»é™¤`opt_llm_config`é…ç½®è¦æ±‚
2. ç§»é™¤`self.optimize_llm`åˆå§‹åŒ–
3. ç§»é™¤`_generate_graph()`æ–¹æ³•
4. ç§»é™¤åŸºç±»ä¸­çš„GPT-4è°ƒç”¨

### æ¡†æ¶å½±å“

**âš ï¸ éœ€è¦ä¿®æ”¹åŸºç±»ç»“æ„**ï¼š

| ç»„ä»¶ | æ”¹åŠ¨ | å½±å“ |
|------|------|------|
| `Optimizer`åŸºç±» | âš ï¸ éœ€è¦ä¿®æ”¹ | åŸºç±»__init__æœŸæœ›opt_llm_config |
| `self.optimize_llm` | âŒ ç§»é™¤ | ç ´ååŸºç±»è®¾è®¡ |
| `_generate_graph()` | âŒ ç§»é™¤ | å…¶ä»–åœ°æ–¹å¯èƒ½è°ƒç”¨ |
| `opt_llm_config` | âŒ ä¸éœ€è¦ | é…ç½®ç»“æ„æ”¹å˜ |

### éœ€è¦æ£€æŸ¥çš„è°ƒç”¨ç‚¹

```bash
# optimizer.pyä¸­å¯èƒ½çš„è°ƒç”¨
self.optimize_llm.call_with_format(...)
self.optimize_llm(...)

# optimizer_rl.pyä¸­çš„è°ƒç”¨
line 191: response = await self._generate_graph(...)  # æ ‡å‡†ç”Ÿæˆ
line 403: return await self._generate_graph(...)  # fallback
line 419: await self.optimize_llm.call_with_format(...)
line 431: await self.optimize_llm(...)
```

**é—®é¢˜**ï¼š
- âŒ ç¬¬191è¡Œæ˜¯æ ‡å‡†ç”Ÿæˆè·¯å¾„ï¼Œå¦‚æœç§»é™¤ä¼šç ´ååŸç‰ˆé€»è¾‘
- âŒ éœ€è¦åœ¨æ‰€æœ‰åœ°æ–¹æ›¿æ¢ä¸ºQwenè°ƒç”¨
- âŒ ç ´åäº†ç»§æ‰¿ç»“æ„

### é…ç½®è¦æ±‚

**ä¸éœ€è¦opt_llm_config**ï¼š

```yaml
environment:
  # âŒ ç§»é™¤opt_llm_configï¼ˆç ´åå‘åå…¼å®¹ï¼‰

  use_dynamic_optimizer: true
  use_qwen_code_generation: true  # æ€»æ˜¯ç”¨Qwen
```

### å‘åå…¼å®¹æ€§

**âŒ ç ´åå‘åå…¼å®¹**ï¼š

| åœºæ™¯ | è¡Œä¸º |
|------|------|
| æ—§é…ç½®ï¼ˆGPT-4æ¨¡å¼ï¼‰ | âŒ ä¸å·¥ä½œ |
| åŸç‰ˆAFlow | âŒ ä¸å…¼å®¹ |
| éœ€è¦é‡æ„ | âœ… æ˜¯ |

---

## å¯¹æ¯”æ€»ç»“

### æ¡†æ¶ç¬¦åˆåº¦

| ç»´åº¦ | é€‰é¡¹1 | é€‰é¡¹3 |
|------|-------|-------|
| ä¿ç•™åŸºç±»ç»“æ„ | âœ… æ˜¯ | âŒ å¦ - éœ€ä¿®æ”¹åŸºç±» |
| ä¿ç•™ç»§æ‰¿å…³ç³» | âœ… æ˜¯ | âš ï¸ å¯èƒ½ç ´å |
| ä¿ç•™åŸç‰ˆé€»è¾‘ | âœ… æ˜¯ï¼ˆå¯é€‰ï¼‰ | âŒ å¦ - ç§»é™¤ |
| å‘åå…¼å®¹ | âœ… 100% | âŒ 0% |
| ä»£ç æ”¹åŠ¨é‡ | âœ… å°ï¼ˆ1ä¸ªæ–¹æ³•ï¼‰ | âŒ å¤§ï¼ˆå¤šä¸ªæ–‡ä»¶ï¼‰ |

### è®­ç»ƒæµç¨‹å®Œæ•´æ€§

| ç»´åº¦ | é€‰é¡¹1 | é€‰é¡¹3 |
|------|-------|-------|
| MCTSä¿ç•™ | âœ… å®Œå…¨ä¿ç•™ | âœ… ä¿ç•™ |
| UCBé€‰æ‹© | âœ… ä¿ç•™ | âœ… ä¿ç•™ |
| ç»éªŒæ±  | âœ… ä¿ç•™ | âœ… ä¿ç•™ |
| è´Ÿå¥–åŠ±æœºåˆ¶ | âœ… æœ‰ | âœ… æœ‰ |
| ç®€åŒ–ç¨‹åº¦ | âœ… 0% | âœ… 0% |

**âœ… ä¸¤è€…åœ¨è®­ç»ƒæµç¨‹ä¸Šç›¸åŒ**

### ç¬¦åˆåˆå¿ƒ

| ç»´åº¦ | é€‰é¡¹1 | é€‰é¡¹3 |
|------|-------|-------|
| Qwenç”Ÿæˆworkflow | âœ… æ˜¯ | âœ… æ˜¯ |
| æ— GPT-4å¹²é¢„ | âœ… æ˜¯ï¼ˆQwenæ¨¡å¼ï¼‰ | âœ… æ˜¯ |
| Qwené€šè¿‡å¤±è´¥å­¦ä¹  | âœ… æ˜¯ | âœ… æ˜¯ |
| è´Ÿå¥–åŠ±åé¦ˆ | âœ… æ˜¯ | âœ… æ˜¯ |

**âœ… ä¸¤è€…åœ¨åˆå¿ƒä¸Šç›¸åŒ**

---

## æ¨èï¼šé€‰é¡¹1

### ç†ç”±

1. **âœ… ç¬¦åˆ"ä¸ç®€åŒ–è®­ç»ƒæµç¨‹"**
   - MCTSå®Œå…¨ä¿ç•™
   - è®­ç»ƒæœºåˆ¶ä¸å˜
   - åªæ˜¯æ¢ä»£ç ç”Ÿæˆå™¨

2. **âœ… ç¬¦åˆ"æ”¹åŠ¨è¦ç¬¦åˆæ•´ä½“æ¡†æ¶"**
   - ä¸ä¿®æ”¹åŸºç±»
   - ä¿ç•™ç»§æ‰¿ç»“æ„
   - ä¿ç•™æ‰€æœ‰åŸç‰ˆç»„ä»¶
   - æ”¹åŠ¨å±€é™åœ¨1ä¸ªæ–¹æ³•

3. **âœ… å‘åå…¼å®¹**
   - æ—§é…ç½®ç»§ç»­å·¥ä½œ
   - åŸç‰ˆAFlowé€»è¾‘ä¿ç•™
   - å¯ä»¥çµæ´»åˆ‡æ¢

4. **âœ… ä½é£é™©**
   - æ”¹åŠ¨å°
   - æµ‹è¯•èŒƒå›´å°
   - å›æ»šå®¹æ˜“

5. **âœ… ç¬¦åˆåˆå¿ƒ**
   - Qwenå®Œå…¨è‡ªä¸»
   - æ— GPT-4å¹²é¢„ï¼ˆQwenæ¨¡å¼ä¸‹ï¼‰
   - è´Ÿå¥–åŠ±é©±åŠ¨å­¦ä¹ 

### é€‰é¡¹3çš„é—®é¢˜

1. **âŒ ç ´åæ¡†æ¶**
   - éœ€è¦ä¿®æ”¹åŸºç±»
   - ç ´åç»§æ‰¿ç»“æ„
   - å¤§èŒƒå›´é‡æ„

2. **âŒ å‘åä¸å…¼å®¹**
   - æ—§é…ç½®ä¸å·¥ä½œ
   - åŸç‰ˆAFlowé€»è¾‘ä¸¢å¤±
   - æ— æ³•åˆ‡æ¢

3. **âŒ é«˜é£é™©**
   - æ”¹åŠ¨å¤§
   - æµ‹è¯•èŒƒå›´å¹¿
   - å¯èƒ½å¼•å…¥bug

4. **âš ï¸ è¿‡åº¦ä¼˜åŒ–**
   - ç§»é™¤äº†"å¯èƒ½ç”¨ä¸åˆ°"çš„ä»£ç 
   - ä½†å¤±å»äº†çµæ´»æ€§
   - ä¸ç¬¦åˆ"ç¬¦åˆæ¡†æ¶"çš„è¦æ±‚

---

## å®æ–½å»ºè®®ï¼šé€‰é¡¹1

### ä¿®æ”¹å†…å®¹

**åªä¿®æ”¹1å¤„**ï¼š`optimizer_rl.py:356-375`

```python
# å½“å‰ä»£ç 
if self.use_qwen_code_generation and self.qwen_code_generator is not None:
    logger.info("[RLEnhancedOptimizer] ğŸ¯ MCTS + Qwen: Using Qwen to generate code directly")

    try:
        qwen_response = await self._generate_code_with_qwen(...)

        if qwen_response is not None:
            logger.info("[RLEnhancedOptimizer] âœ… Qwen code generation successful")
            return qwen_response
        else:
            logger.warning("[RLEnhancedOptimizer] âš ï¸ Qwen code generation failed, falling back to GPT-4")

    except Exception as e:
        logger.error(f"[RLEnhancedOptimizer] âŒ Error in Qwen code generation: {e}")
        logger.warning("[RLEnhancedOptimizer] Falling back to GPT-4")

# åŸç‰ˆæµç¨‹ï¼šä½¿ç”¨GPT-4
return await self._generate_graph(enhanced_prompt)
```

**ä¿®æ”¹ä¸º**ï¼š

```python
# MCTS + Qwen: ä½¿ç”¨Qwenç›´æ¥ç”Ÿæˆä»£ç ï¼ˆæ— GPT-4 fallbackï¼‰
if self.use_qwen_code_generation and self.qwen_code_generator is not None:
    logger.info("[RLEnhancedOptimizer] ğŸ¯ MCTS + Qwen: Using Qwen to generate code directly (no GPT-4 fallback)")

    try:
        qwen_response = await self._generate_code_with_qwen(...)

        if qwen_response is not None:
            logger.info("[RLEnhancedOptimizer] âœ… Qwen code generation successful")
            return qwen_response
        else:
            # âœ… ä¸fallback - è¿”å›å¤±è´¥ç»“æœè®©Qwenå­¦ä¹ 
            logger.warning("[RLEnhancedOptimizer] âš ï¸ Qwen failed to generate valid code")
            logger.info("[RLEnhancedOptimizer] ğŸ“š Returning empty workflow for negative reward signal")

            return {
                'modification': 'Failed to generate valid code - syntax errors',
                'graph': '''class Workflow:
    def __init__(self, name: str, llm_config, dataset: str) -> None:
        pass

    async def __call__(self, problem: str, entry_point=None):
        # Empty workflow - will get zero score
        return "", 0.0''',
                'prompt': ''
            }

    except Exception as e:
        logger.error(f"[RLEnhancedOptimizer] âŒ Error in Qwen code generation: {e}")
        logger.info("[RLEnhancedOptimizer] ğŸ“š Returning empty workflow for negative reward signal")

        return {
            'modification': f'Code generation error: {str(e)}',
            'graph': '''class Workflow:
    def __init__(self, name: str, llm_config, dataset: str) -> None:
        pass

    async def __call__(self, problem: str, entry_point=None):
        return "", 0.0''',
            'prompt': ''
        }

# åŸç‰ˆæµç¨‹ï¼šä½¿ç”¨GPT-4ï¼ˆå‘åå…¼å®¹ï¼Œuse_qwen_code_generation=falseæ—¶ï¼‰
return await self._generate_graph(enhanced_prompt)
```

### é…ç½®ä¸å˜

```yaml
# ä»ç„¶éœ€è¦opt_llm_configï¼ˆå‘åå…¼å®¹ï¼‰
environment:
  opt_llm_config:
    model: "gpt-4o-mini"
    key: "${OPENAI_API_KEY}"

  use_dynamic_optimizer: true
  use_qwen_code_generation: true  # å¯ç”¨Qwenï¼Œä¸ä¼šfallback
```

### æ•ˆæœ

**Qwenå¤±è´¥æ—¶**ï¼š
```
[RLEnhancedOptimizer] âš ï¸ Qwen failed to generate valid code
[RLEnhancedOptimizer] ğŸ“š Returning empty workflow for negative reward signal
[DeepWorkflowEnv] Executing workflow...
[DeepWorkflowEnv] Score: 0.0000
[RLTrainer] Reward: -1.0 (å¼ºè´Ÿå¥–åŠ±)
[PPO] Updating policy...
```

**ä¸‹æ¬¡Qwenä¼š**ï¼š
- âœ… å­¦ä¹ é¿å…è¯­æ³•é”™è¯¯
- âœ… å­¦ä¹ ç”Ÿæˆæ­£ç¡®ä»£ç 
- âœ… æ²¡æœ‰GPT-4å¸®åŠ©

---

## æ€»ç»“

| æ ‡å‡† | é€‰é¡¹1 | é€‰é¡¹3 |
|------|-------|-------|
| **ä¸ç®€åŒ–è®­ç»ƒæµç¨‹** | âœ… æ˜¯ | âœ… æ˜¯ |
| **ç¬¦åˆæ•´ä½“æ¡†æ¶** | âœ… å®Œå…¨ç¬¦åˆ | âŒ ç ´åæ¡†æ¶ |
| **å‘åå…¼å®¹** | âœ… 100% | âŒ 0% |
| **æ”¹åŠ¨é‡** | âœ… å° | âŒ å¤§ |
| **é£é™©** | âœ… ä½ | âŒ é«˜ |
| **ç¬¦åˆåˆå¿ƒ** | âœ… æ˜¯ | âœ… æ˜¯ |

**âœ… æ¨èé€‰é¡¹1**

---

**æ˜¯å¦ç«‹å³å®æ–½é€‰é¡¹1çš„ä¿®æ”¹ï¼Ÿ**
