# AIME优化训练使用说明

## ⚠️ 重要修复

已修复关键Bug：之前的训练对数学任务错误使用了代码生成器，导致0%准确率。
现在使用正确的Custom operator让GPT-4o-mini直接推理数学问题。

**预期效果**: 基准准确率10-20%（vs 之前的0%）

详见：`修复说明.md`

## 🚀 快速开始

### 1. 设置环境

```bash
export OPENAI_API_KEY='your-api-key'
cd /root/agentflow/integration
```

### 2. 启动训练

```bash
./启动优化训练.sh
```

选择前台或后台运行。

### 3. 监控进度

```bash
./监控训练.sh
```

## 📁 核心文件

- `优化运行.yaml` - 训练配置
- `优化训练.py` - 训练脚本
- `启动优化训练.sh` - 启动脚本
- `监控训练.sh` - 监控工具

## ✨ 主要优化

1. **课程学习**: 4题→8题→12题，逐步增加难度
2. **奖励塑形**: 接近正确答案也给奖励，避免全0
3. **更好的超参数**: 更高学习率和探索性
4. **检查点保存**: 每个epoch都保存

## 📊 输出位置

`/content/drive/MyDrive/agentflow/outputs/optimized_training/`

## ⚙️ 调整配置

编辑 `优化运行.yaml` 修改参数：

```yaml
# 学习率
rl:
  learning_rate: 0.0003

# 课程学习
curriculum:
  stages:
    - epoch: 1-5
      sample_size: 4
```

## 🔍 常见问题

**Q: 奖励始终为0?**
A: 增加 `baseline_reward` 到 0.05

**Q: 训练太慢?**
A: 减少 `max_rounds` 到 5，减少 `sample_size`

**Q: GPU内存不足?**
A: 减小 `batch_size` 到 4

## 📈 预期效果

- Epoch 1-5: avg_score > 0.05
- Epoch 6-10: avg_score > 0.15
- Epoch 11-20: avg_score > 0.30

明天训练愉快！🎉
